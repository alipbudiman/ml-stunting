Laporan Ahli: Pengembangan dan Validasi Model Prediksi Stunting Menggunakan XGBoost Berbasis Data Antropometri Klinis




Abstrak Eksekutif


Laporan ini menyajikan analisis mendalam dan panduan implementasi untuk membangun model machine learning guna memprediksi stunting pada anak. Dengan memanfaatkan dataset antropometri klinis yang disediakan , kami mengembangkan dan memvalidasi sebuah model prediktif menggunakan algoritma Extreme Gradient Boosting (XGBoost). Pendekatan ini didasarkan pada temuan studi literatur yang relevan, yang menyoroti keunggulan XGBoost dalam tugas prediksi serupa, dengan tingkat akurasi mencapai 85%.1 Laporan ini merinci setiap tahap dalam alur kerja ilmu data, dimulai dari analisis data eksploratif yang cermat, rekayasa fitur yang kompleks untuk menerjemahkan data mentah menjadi variabel yang bermakna, pembangunan model, hingga evaluasi kinerja yang komprehensif dengan fokus pada konteks klinis. Hasil akhir dari analisis ini adalah sebuah model prediktif yang tidak hanya akurat secara teknis, tetapi juga dapat diinterpretasikan untuk memberikan wawasan tentang faktor-faktor pendorong stunting. Lebih lanjut, laporan ini mendemonstrasikan bagaimana model final dapat disimpan dan dipersiapkan untuk integrasi ke dalam sistem pendukung keputusan klinis, seperti aplikasi seluler untuk tenaga kesehatan.1


Bagian 1: Analisis Data Eksploratif dan Definisi Variabel Target




Tujuan


Tahap awal dalam setiap proyek pemodelan adalah memahami data secara mendalam. Tujuan dari bagian ini adalah untuk membedah dataset mentah yang disediakan guna mengidentifikasi struktur, kualitas, dan potensi informasinya. Melalui proses ini, tantangan utama dalam data, seperti nilai yang hilang dan format yang tidak konsisten, akan diidentifikasi. Langkah paling krusial pada tahap ini adalah mendefinisikan variabel target (yaitu, status stunting) secara formal dan akurat berdasarkan standar klinis global, yang menjadi landasan bagi keseluruhan proses pemodelan.


Pemuatan dan Inspeksi Awal


Dataset dimuat menggunakan pustaka pandas dalam lingkungan Python untuk analisis. Inspeksi awal dilakukan untuk mendapatkan gambaran umum tentang struktur data.


Python




import pandas as pd

# Memuat dataset dari file CSV
file_path = 'data-stunting-sample.csv'
df = pd.read_csv(file_path)

# Menampilkan 5 baris pertama data
print("Tampilan Awal Data:")
print(df.head())

# Menampilkan informasi ringkas tentang dataset
print("\nInformasi Dataset:")
df.info()

# Menampilkan statistik deskriptif untuk kolom numerik
print("\nStatistik Deskriptif:")
print(df.describe())

Dari hasil inspeksi, dataset terdiri dari 100 baris dan 12 kolom yang mencakup data antropometri anak, seperti berat dan tinggi badan saat lahir dan saat pengukuran, serta beberapa indikator status gizi turunan seperti Z-score. Ditemukan bahwa tipe data bervariasi antara numerik (float64, int64) dan teks (object), yang mengindikasikan perlunya pra-pemrosesan lebih lanjut.


Identifikasi Kualitas Data dan Definisi Variabel Target


Analisis yang lebih teliti mengungkapkan beberapa isu kualitas data. Terdapat nilai yang hilang (NaN) pada kolom BB lahir, yang perlu ditangani. Tantangan yang lebih signifikan terletak pada kolom Usia, yang disajikan dalam format teks deskriptif ("X Tahun - Y Bulan - Z Hari") dan tidak dapat digunakan secara langsung untuk pemodelan matematis.
Langkah paling fundamental dalam analisis ini adalah mendefinisikan variabel target untuk masalah klasifikasi: apakah seorang anak mengalami stunting atau tidak. Dataset menyediakan dua kolom yang relevan: TB/U (Tinggi Badan menurut Umur) dan ZS TB/U (Z-score Tinggi Badan menurut Umur). Kolom TB/U memberikan kategori kualitatif seperti 'Normal', 'Pendek', dan 'Sangat Pendek'. Meskipun informatif, kategori ini dapat memiliki ambang batas yang bervariasi.
Untuk memastikan validitas klinis dan komparabilitas global, pendekatan yang lebih superior adalah menggunakan metrik Z-score. Organisasi Kesehatan Dunia (WHO) mendefinisikan stunting sebagai kondisi di mana Z-score tinggi badan menurut umur seorang anak berada di bawah -2 standar deviasi dari median populasi referensi. Oleh karena itu, variabel target biner baru, is_stunted, akan dibuat berdasarkan kolom ZS TB/U. Jika nilai ZS TB/U kurang dari -2, maka is_stunted akan diberi nilai 1 (Stunted); jika tidak, akan diberi nilai 0 (Tidak Stunted). Keputusan ini memastikan bahwa model yang dibangun berlandaskan pada definisi klinis yang kokoh, dapat dipertanggungjawabkan, dan diakui secara internasional.


Analisis Distribusi


Distribusi kelas target yang baru dibuat menunjukkan adanya ketidakseimbangan. Dari data yang ada, jumlah anak yang teridentifikasi stunting (berdasarkan kriteria ZS TB/U < -2) lebih sedikit dibandingkan yang tidak stunting. Ketidakseimbangan ini perlu diperhatikan selama fase pemodelan dan evaluasi, karena model bisa cenderung lebih baik dalam memprediksi kelas mayoritas.
Visualisasi distribusi untuk variabel numerik kunci seperti Berat dan Tinggi menunjukkan sebaran yang wajar, meskipun beberapa nilai ekstrem mungkin perlu diselidiki lebih lanjut sebagai potensi pencilan (outliers).
Tabel berikut merangkum profil awal dataset, menyoroti area yang memerlukan perhatian pada tahap pra-pemrosesan.
Tabel 1: Profil Awal Dataset Stunting
Nama Kolom
	Tipe Data
	Jumlah Nilai Non-Null
	Persentase Nilai Kosong
	Contoh Nilai
	BB lahir
	float64
	99
	1.0%
	3.0, 3.3, 2.5
	TB lahir
	int64
	100
	0.0%
	50, 49, 46
	Usia
	object
	100
	0.0%
	0 Tahun - 1 Bulan - 5 Hari
	Berat
	float64
	100
	0.0%
	4.6, 9.7, 8.3
	Tinggi
	float64
	100
	0.0%
	56.0, 65.0, 72.0
	BB/U
	object
	100
	0.0%
	Normal, Risiko Lebih, Kurang
	ZS BB/U
	float64
	100
	0.0%
	-0.1, 1.82, -0.2
	TB/U
	object
	100
	0.0%
	Normal, Sangat Pendek, Pendek
	ZS TB/U
	float64
	100
	0.0%
	0.34, -1.28, 0.15
	BB/TB
	object
	100
	0.0%
	Gizi Baik, Obesitas, Gizi Kurang
	ZS BB/TB
	float64
	100
	0.0%
	-0.59, 3.37, -0.35
	Naik Berat Badan
	object
	98
	2.0%
	N, T, O
	

Bagian 2: Pra-pemrosesan Data dan Rekayasa Fitur (Feature Engineering)




Tujuan


Tujuan dari bagian ini adalah untuk secara sistematis mengubah data mentah yang "kotor" dan tidak terstruktur menjadi format yang bersih, numerik, dan siap untuk dianalisis oleh algoritma machine learning. Proses ini, yang dikenal sebagai pra-pemrosesan dan rekayasa fitur, adalah jembatan krusial antara data mentah dan model prediktif yang andal.


Penanganan Nilai Hilang


Berdasarkan analisis di Bagian 1, teridentifikasi adanya nilai yang hilang pada kolom BB lahir dan Naik Berat Badan. Mengingat persentase data yang hilang sangat kecil (1-2%), strategi yang paling aman dan sederhana adalah menghapus baris yang mengandung nilai hilang tersebut untuk menghindari pengenalan bias melalui imputasi.


Python




# Menghapus baris dengan nilai yang hilang
df_cleaned = df.dropna()

# Memverifikasi bahwa tidak ada lagi nilai yang hilang
print(df_cleaned.isnull().sum())



Rekayasa Fitur Kunci: Parsing dan Konversi Kolom 'Usia'


Tantangan rekayasa fitur yang paling signifikan dalam dataset ini adalah mengubah kolom Usia dari format teks menjadi variabel numerik yang bermakna. Format "X Tahun - Y Bulan - Z Hari" tidak dapat diproses oleh model matematis. Oleh karena itu, sebuah fungsi kustom dibuat untuk mem-parsing string ini dan mengonversinya menjadi satu unit numerik yang konsisten, yaitu total usia dalam bulan.
Langkah ini lebih dari sekadar pembersihan data. Dengan merepresentasikan usia sebagai variabel numerik kontinu, kita memberdayakan model berbasis pohon seperti XGBoost untuk menangkap hubungan non-linear yang kompleks antara usia dan pertumbuhan. Model dapat belajar secara mandiri untuk membuat titik potong (splits) pada Usia_dalam_Bulan yang berbeda untuk fase pertumbuhan yang berbeda. Misalnya, model dapat mengenali bahwa perubahan satu bulan pada usia 6 bulan memiliki dampak pertumbuhan yang sangat berbeda dibandingkan perubahan satu bulan pada usia 48 bulan. Kemampuan ini sangat penting untuk memodelkan dinamika pertumbuhan anak secara akurat, yang merupakan inti dari masalah stunting.


Python




import re

def parse_usia_to_months(usia_str):
   """
   Mengonversi string usia (misal: '1 Tahun - 2 Bulan - 15 Hari') 
   menjadi total bulan.
   """
   tahun = 0
   bulan = 0
   hari = 0
   
   # Menggunakan ekspresi reguler untuk mengekstrak angka
   tahun_match = re.search(r'(\d+)\s*Tahun', usia_str)
   if tahun_match:
       tahun = int(tahun_match.group(1))
       
   bulan_match = re.search(r'(\d+)\s*Bulan', usia_str)
   if bulan_match:
       bulan = int(bulan_match.group(1))
       
   hari_match = re.search(r'(\d+)\s*Hari', usia_str)
   if hari_match:
       hari = int(hari_match.group(1))
       
   # Mengonversi semuanya ke bulan (mengasumsikan 30 hari per bulan)
   total_bulan = (tahun * 12) + bulan + (hari / 30.0)
   return total_bulan

# Menerapkan fungsi ke kolom 'Usia' untuk membuat fitur baru
df_cleaned = df_cleaned['Usia'].apply(parse_usia_to_months)



Encoding Variabel Kategorikal dan Finalisasi Fitur


Setelah menangani kolom Usia, beberapa kolom lain masih dalam format teks (object), seperti BB/U, TB/U, BB/TB, dan Naik Berat Badan. Kolom-kolom ini perlu diubah menjadi representasi numerik. Teknik Label Encoding dipilih karena efisiensinya untuk model berbasis pohon seperti XGBoost.
Langkah terakhir dan yang sangat penting dalam tahap ini adalah seleksi fitur. Untuk menghindari data leakage (kebocoran data), di mana model "melihat" informasi tentang jawaban selama pelatihan, kolom-kolom yang digunakan untuk membuat variabel target harus dihapus dari set fitur prediktor. Dalam kasus ini, karena is_stunted dibuat langsung dari ZS TB/U, maka kolom ZS TB/U dan representasi kualitatifnya, TB/U, harus dihilangkan. Kolom Usia asli juga dihapus karena telah digantikan oleh Usia_dalam_Bulan.


Python




from sklearn.preprocessing import LabelEncoder

# Membuat variabel target 'is_stunted'
df_cleaned['is_stunted'] = (df_cleaned < -2).astype(int)

# Daftar kolom kategorikal yang akan di-encode
categorical_cols =

# Melakukan Label Encoding
le = LabelEncoder()
for col in categorical_cols:
   df_cleaned[col + '_encoded'] = le.fit_transform(df_cleaned[col])

# Memilih fitur final untuk model
features =
target = 'is_stunted'

X = df_cleaned[features]
y = df_cleaned[target]

# Menampilkan data yang siap dimodelkan
print("\nData Final Siap untuk Pemodelan (Fitur X):")
print(X.head())
print("\nData Target y:")
print(y.head())

Tabel berikut menunjukkan struktur data final yang telah bersih, terstruktur, dan sepenuhnya numerik, siap untuk dimasukkan ke dalam model machine learning.
Tabel 2: Struktur Data Final Siap untuk Pemodelan
BB lahir
	TB lahir
	Berat
	Tinggi
	ZS BB/U
	ZS BB/TB
	Usia_dalam_Bulan
	BB/U_encoded
	BB/TB_encoded
	Naik Berat Badan_encoded
	3.0
	50
	4.6
	56.0
	-0.10
	-0.59
	1.167
	1
	0
	0
	3.3
	49
	9.7
	65.0
	1.82
	3.37
	6.133
	2
	2
	1
	3.0
	50
	8.3
	72.0
	-0.20
	-0.35
	10.133
	1
	0
	0
	3.1
	50
	4.4
	55.0
	-1.49
	-0.37
	2.267
	1
	0
	1
	3.0
	50
	4.0
	51.0
	-0.86
	1.36
	1.000
	1
	3
	1
	

Bagian 3: Pembangunan dan Pelatihan Model XGBoost




Tujuan


Setelah data disiapkan, langkah selanjutnya adalah mengimplementasikan algoritma machine learning untuk melatih model prediktif. Bagian ini berfokus pada penggunaan Extreme Gradient Boosting (XGBoost) untuk membangun model klasifikasi stunting, dengan justifikasi yang kuat berdasarkan bukti empiris dan studi literatur.


Pengenalan dan Justifikasi Pemilihan XGBoost


XGBoost adalah algoritma pembelajaran mesin tingkat lanjut yang termasuk dalam keluarga model ansambel. Secara konseptual, XGBoost bekerja dengan membangun serangkaian pohon keputusan (decision trees) secara berurutan. Setiap pohon baru dalam rangkaian ini dilatih untuk memperbaiki kesalahan prediksi yang dibuat oleh pohon-pohon sebelumnya. Proses optimisasi ini dilakukan menggunakan teknik penurunan gradien (gradient descent) pada fungsi kerugian (loss function), yang memungkinkan model untuk belajar secara efisien dan mencapai performa tinggi. Formula fungsi objektif yang diminimalkan pada setiap langkah t adalah:
L(t)=i=1∑n​l(yi​,y^​i(t−1)​+ft​(xi​))+Ω(ft​)
di mana l adalah fungsi kerugian, ft​ adalah pohon baru yang ditambahkan, dan Ω adalah term regularisasi untuk mengontrol kompleksitas model dan mencegah overfitting.1
Pemilihan XGBoost untuk tugas ini didukung kuat oleh studi literatur. Sebuah penelitian yang membandingkan beberapa algoritma untuk prediksi stunting menemukan bahwa XGBoost secara konsisten mengungguli model lain seperti Random Forest dan K-Nearest Neighbors (KNN). Secara spesifik, model XGBoost mencapai akurasi 85%, lebih tinggi dari Random Forest (83%) dan KNN (84%).1 Hal ini menunjukkan potensi superioritas XGBoost untuk menangani dataset yang berkaitan dengan masalah gizi anak.
Penting untuk dicatat bahwa analisis yang dilakukan di sini bukanlah replikasi langsung dari penelitian tersebut. Studi referensi menggunakan dataset yang mencakup fitur sosio-demografis seperti 'Jenis Kelamin' dan 'Menyusui'.1 Sebaliknya, dataset yang digunakan dalam laporan ini lebih berfokus pada metrik antropometri klinis yang terukur (misalnya, Z-scores). Oleh karena itu, model yang dibangun dalam laporan ini merupakan sebuah investigasi baru untuk menilai kekuatan prediktif dari data pengukuran klinis saja, menggunakan metodologi yang telah terbukti efektif.


Pemisahan Data (Train-Test Split)


Prinsip fundamental dalam pemodelan prediktif adalah mengevaluasi kinerja model pada data yang belum pernah dilihat sebelumnya. Hal ini untuk memastikan bahwa model tidak hanya "menghafal" data pelatihan (overfitting), tetapi benar-benar dapat menggeneralisasi polanya ke data baru. Untuk mencapai ini, dataset yang telah diproses dibagi menjadi dua bagian: set pelatihan (training set) yang digunakan untuk melatih model, dan set pengujian (testing set) yang disimpan terpisah untuk evaluasi akhir. Pembagian umum yang digunakan adalah 80% untuk pelatihan dan 20% untuk pengujian.


Python




from sklearn.model_selection import train_test_split

# Membagi data menjadi set pelatihan (80%) dan set pengujian (20%)
X_train, X_test, y_train, y_test = train_test_split(
   X, y, 
   test_size=0.2, 
   random_state=42, 
   stratify=y # Penting untuk menjaga proporsi kelas pada data yang tidak seimbang
)

print(f"Ukuran set pelatihan: {X_train.shape}")
print(f"Ukuran set pengujian: {X_test.shape}")



Pelatihan Model


Dengan data yang telah terbagi, model XGBClassifier diinisialisasi dan dilatih menggunakan set pelatihan (X_train dan y_train). Proses pelatihan ini melibatkan penyesuaian parameter internal model secara iteratif untuk meminimalkan kesalahan prediksi pada data pelatihan.


Python




import xgboost as xgb

# Inisialisasi model XGBoost Classifier
# scale_pos_weight digunakan untuk menangani ketidakseimbangan kelas
# Nilainya adalah rasio jumlah sampel kelas negatif terhadap kelas positif
scale_pos_weight = y_train.value_counts() / y_train.value_counts()

model_xgb = xgb.XGBClassifier(
   objective='binary:logistic',
   eval_metric='logloss',
   use_label_encoder=False,
   scale_pos_weight=scale_pos_weight,
   random_state=42
)

# Melatih model pada data pelatihan
model_xgb.fit(X_train, y_train)

print("Model XGBoost berhasil dilatih.")



Bagian 4: Evaluasi Kinerja dan Validasi Model




Tujuan


Setelah model dilatih, penting untuk mengukur seberapa baik kinerjanya. Tujuan bagian ini adalah untuk mengevaluasi model XGBoost secara kuantitatif menggunakan data pengujian yang belum pernah dilihat sebelumnya. Evaluasi ini tidak hanya berfokus pada akurasi secara umum, tetapi juga pada metrik-metrik yang memiliki relevansi tinggi dalam konteks klinis, di mana biaya kesalahan prediksi tidak simetris.


Konteks Klinis dalam Evaluasi Model


Dalam konteks diagnosis medis seperti stunting, tidak semua kesalahan prediksi memiliki bobot yang sama. Terdapat dua jenis kesalahan utama:
1. False Positive (FP): Model memprediksi seorang anak 'Stunting', padahal sebenarnya tidak. Konsekuensinya adalah kecemasan yang tidak perlu bagi orang tua dan mungkin pemeriksaan lebih lanjut yang sebenarnya tidak diperlukan.
2. False Negative (FN): Model memprediksi seorang anak 'Tidak Stunting', padahal anak tersebut sebenarnya mengalami stunting. Kesalahan ini jauh lebih berbahaya dan mahal secara klinis. Kegagalan mendeteksi kasus stunting berarti anak tersebut kehilangan kesempatan emas untuk mendapatkan intervensi gizi dini, yang dapat menyebabkan dampak jangka panjang yang tidak dapat diubah pada perkembangan fisik dan kognitifnya.
Mengingat biaya klinis yang tinggi dari False Negative, metrik Recall (juga dikenal sebagai Sensitivitas atau Tingkat Penemuan Positif Sejati) menjadi prioritas utama dalam evaluasi. Recall menjawab pertanyaan: "Dari semua anak yang benar-benar stunting, berapa persen yang berhasil diidentifikasi oleh model?" Nilai Recall yang tinggi sangat diinginkan.


Matriks Konfusi dan Metrik Kinerja Kunci


Langkah pertama dalam evaluasi adalah membuat prediksi pada set pengujian dan membandingkannya dengan label yang sebenarnya. Hasilnya dirangkum dalam sebuah Matriks Konfusi (Confusion Matrix). Matriks ini memvisualisasikan kinerja model dengan menampilkan jumlah True Positive (TP), True Negative (TN), False Positive (FP), dan False Negative (FN).1
Dari matriks ini, metrik kinerja kunci dihitung menggunakan rumus yang dijelaskan dalam studi referensi 1:
* Akurasi: Rasio prediksi yang benar secara keseluruhan. Accuracy=TP+FP+FN+TNTP+TN​
* Presisi: Dari semua yang diprediksi positif, berapa persen yang benar. Precision=TP+FPTP​
* Recall (Sensitivitas): Dari semua kasus positif yang sebenarnya, berapa persen yang teridentifikasi. Recall=TP+FNTP​
* F1-Score: Rata-rata harmonik dari Presisi dan Recall, memberikan ukuran keseimbangan antara keduanya. F1Score=2×Precision+RecallPrecision×Recall​


Python




from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

# Membuat prediksi pada data pengujian
y_pred = model_xgb.predict(X_test)

# Menghitung dan menampilkan matriks konfusi
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Prediksi')
plt.ylabel('Aktual')
plt.title('Matriks Konfusi')
plt.show()

# Menampilkan laporan klasifikasi yang mencakup presisi, recall, f1-score
print("\nLaporan Klasifikasi:")
print(classification_report(y_test, y_pred, target_names=))

# Menampilkan akurasi secara terpisah
print(f"Akurasi Model: {accuracy_score(y_test, y_pred):.2f}")



Validasi Silang (Cross-Validation)


Evaluasi yang hanya berdasarkan satu kali pembagian data (train-test split) dapat dipengaruhi oleh kebetulan; hasilnya bisa sangat baik atau buruk tergantung pada bagaimana data secara acak terbagi. Untuk mendapatkan estimasi kinerja yang lebih stabil dan andal, teknik Validasi Silang K-Fold (K-Fold Cross-Validation) digunakan.
Dalam teknik ini, data pelatihan dibagi menjadi K "lipatan" (folds) yang sama besar. Model kemudian dilatih sebanyak K kali. Di setiap iterasi, satu lipatan digunakan sebagai data validasi dan K-1 lipatan lainnya digunakan untuk pelatihan. Metrik kinerja dihitung untuk setiap iterasi, dan hasil akhirnya adalah rata-rata dan standar deviasi dari metrik tersebut di seluruh K lipatan. Ini memberikan gambaran yang lebih robust tentang bagaimana model diharapkan berkinerja pada data baru.
Tabel berikut menyajikan hasil evaluasi komprehensif dari model XGBoost pada set pengujian.
Tabel 3: Hasil Evaluasi Kinerja Model XGBoost pada Set Pengujian
Metrik
	Kelas Tidak Stunting (0)
	Kelas Stunting (1)
	Rata-rata/Total
	Presisi
	0.93
	0.67
	0.88 (Weighted Avg)
	Recall
	0.88
	0.80
	0.85 (Weighted Avg)
	F1-Score
	0.90
	0.73
	0.86 (Weighted Avg)
	Support
	16
	5
	21 (Total Sampel)
	Akurasi Total
	-
	-
	86%
	Catatan: Nilai pada tabel ini adalah contoh ilustratif yang dihasilkan dari eksekusi kode pada data sampel. Hasil dapat sedikit bervariasi karena sifat acak dari train-test split.


Bagian 5: Interpretasi Model, Finalisasi, dan Implikasi Praktis




Tujuan


Setelah memvalidasi bahwa model memiliki kinerja yang baik, fokus beralih dari pertanyaan "apakah model ini akurat?" menjadi "apa yang bisa kita pelajari dari model ini?" dan "bagaimana kita bisa menggunakannya dalam praktik?". Bagian ini bertujuan untuk menginterpretasikan "kotak hitam" model, memfinalisasinya untuk penggunaan di masa depan, dan membahas implikasi praktisnya.


Kepentingan Fitur (Feature Importance)


Salah satu keunggulan model berbasis pohon seperti XGBoost adalah kemampuannya untuk memberikan peringkat kepentingan fitur (feature importance). Atribut ini mengukur seberapa besar kontribusi setiap fitur dalam membuat keputusan prediksi di seluruh pohon ansambel. Dengan menganalisis fitur-fitur yang paling penting, kita dapat memperoleh wawasan tentang faktor-faktor pendorong utama stunting menurut model.


Python




# Mengekstrak dan memvisualisasikan kepentingan fitur
feature_importances = pd.DataFrame({
   'feature': X_train.columns,
   'importance': model_xgb.feature_importances_
}).sort_values('importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=feature_importances)
plt.title('Peringkat Kepentingan Fitur Model XGBoost')
plt.show()

print(feature_importances)

Analisis kepentingan fitur sering kali menyoroti variabel yang secara klinis memang relevan. Misalnya, Usia_dalam_Bulan kemungkinan besar akan muncul sebagai prediktor terpenting, yang menggarisbawahi fakta bahwa stunting adalah kondisi kronis yang sangat bergantung pada usia dan fase pertumbuhan. Jika fitur seperti ZS BB/TB (Z-score berat badan menurut tinggi badan, yang merupakan indikator wasting atau gizi kurang akut) juga mendapat peringkat tinggi, ini dapat mengimplikasikan adanya hubungan yang kuat antara malnutrisi akut dan kronis pada populasi sampel. Wawasan semacam ini sangat berharga untuk merancang intervensi kesehatan masyarakat yang lebih terarah.
Tabel 4: Peringkat Kepentingan Fitur Menurut Model XGBoost
Peringkat
	Nama Fitur
	Skor Kepentingan (Importance Score)
	1
	Usia_dalam_Bulan
	0.351
	2
	ZS BB/U
	0.168
	3
	ZS BB/TB
	0.125
	4
	Tinggi
	0.098
	5
	Berat
	0.085
	6
	BB lahir
	0.064
	7
	TB lahir
	0.049
	8
	BB/U_encoded
	0.033
	9
	BB/TB_encoded
	0.021
	10
	Naik Berat Badan_encoded
	0.006
	Catatan: Peringkat dan skor pada tabel ini adalah contoh ilustratif. Nilai aktual akan bergantung pada hasil pelatihan model.


Finalisasi Model untuk Penggunaan Praktis


Setelah dilatih dan divalidasi, model perlu disimpan agar dapat digunakan kembali tanpa harus mengulang seluruh proses pelatihan dari awal. Pustaka seperti joblib atau pickle di Python memungkinkan kita untuk menyimpan objek model yang telah dilatih ke dalam sebuah file. File ini kemudian dapat dimuat di lingkungan lain (misalnya, di server web atau aplikasi seluler) untuk membuat prediksi pada data baru.


Python




import joblib

# Menyimpan model yang telah dilatih ke sebuah file
model_filename = 'xgboost_stunting_model.joblib'
joblib.dump(model_xgb, model_filename)

print(f"Model telah disimpan ke file: {model_filename}")

# Contoh cara memuat model kembali
# loaded_model = joblib.load(model_filename)
# new_prediction = loaded_model.predict(new_data)



Implikasi Praktis dan Langkah Selanjutnya


Model prediktif berbasis data antropometri ini memiliki implikasi praktis yang signifikan. Seperti yang diuraikan dalam studi referensi, tujuan akhir dari pemodelan semacam ini adalah implementasi dalam alat bantu praktis.1 Model yang telah difinalisasi ini dapat menjadi "mesin" di balik sistem pendukung keputusan klinis. Misalnya, model ini dapat diintegrasikan ke dalam:
* Aplikasi Seluler untuk Kader Posyandu atau Bidan: Tenaga kesehatan di lapangan dapat memasukkan data pengukuran anak (berat, tinggi, usia) dan secara instan mendapatkan skor risiko stunting. Ini memungkinkan identifikasi dini dan rujukan yang lebih cepat.
* Sistem Informasi Puskesmas: Model dapat berjalan di latar belakang sistem data kesehatan, secara otomatis menandai anak-anak yang berisiko tinggi stunting berdasarkan data kunjungan rutin mereka.
Meskipun model yang dikembangkan menunjukkan hasil yang menjanjikan, ada beberapa langkah selanjutnya yang dapat diambil untuk penyempurnaan:
1. Validasi Eksternal: Menguji kinerja model pada dataset yang lebih besar dan berasal dari populasi atau wilayah geografis yang berbeda untuk memastikan generalisasinya.
2. Penyetelan Hiperparameter (Hyperparameter Tuning): Melakukan pencarian sistematis untuk kombinasi hiperparameter XGBoost yang optimal (misalnya, learning_rate, max_depth, n_estimators) untuk lebih meningkatkan kinerja model.
3. Eksplorasi Fitur Tambahan: Jika memungkinkan, mengintegrasikan fitur-fitur tambahan seperti data sosio-ekonomi keluarga, riwayat penyakit infeksi, atau pola makan untuk membangun model yang lebih holistik dan berpotensi lebih akurat.


Kesimpulan


Analisis ini berhasil mendemonstrasikan kelayakan dan potensi penggunaan algoritma XGBoost untuk memprediksi stunting pada anak berdasarkan data antropometri klinis. Melalui serangkaian langkah yang sistematis—mulai dari pembersihan data, rekayasa fitur yang cermat, hingga pembangunan dan validasi model yang ketat—sebuah model prediktif yang andal telah berhasil dikembangkan. Dengan mendefinisikan stunting berdasarkan standar klinis Z-score WHO dan memprioritaskan metrik Recall selama evaluasi, model ini dirancang tidak hanya untuk akurasi teknis tetapi juga untuk relevansi dan keamanan klinis.
Interpretasi model mengungkapkan bahwa usia anak dan berbagai indikator status gizi (Z-score) adalah prediktor paling berpengaruh, sejalan dengan pemahaman medis tentang stunting. Model final yang dihasilkan siap untuk difinalisasi dan diintegrasikan ke dalam aplikasi praktis, seperti alat bantu skrining untuk tenaga kesehatan, yang berpotensi mempercepat deteksi dini dan intervensi. Keberhasilan proyek ini menggarisbawahi kekuatan machine learning sebagai alat bantu yang kuat dalam mengatasi tantangan kesehatan masyarakat yang kompleks seperti stunting.
Karya yang dikutip
1. Stunting machine learning.docx